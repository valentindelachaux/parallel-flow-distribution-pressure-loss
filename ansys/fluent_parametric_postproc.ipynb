{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.interpolate as sci\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import jou_gen as jg\n",
    "import param_postproc as ppproc\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../RD-systems-and-test-benches/utils')\n",
    "import plot_functions as pfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\ANSYS Fluent Projects\\Hydraulics\\V4.5\\1MPE_woch'\n",
    "\n",
    "df = pd.read_excel(folder_path+'\\\\1MPE_woch_tui-parametric.xlsx')\n",
    "df.rename(columns={x : f'VAR_{x}' for x in list(df.columns)[5:]},inplace=True)\n",
    "df = df.loc[:, ~df.columns.str.startswith('VAR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = np.arange(51,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jg.convert_residuals_csv(folder_path+'\\\\parametric',liste)\n",
    "# jg.convert_report(folder_path+'\\\\parametric','mdot_report',liste)\n",
    "# jg.convert_report(folder_path+'\\\\parametric','pressure_report',liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_report = {}\n",
    "mdot_report = {}\n",
    "pressure_report = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    residuals_report[df.loc[i, 'Name']] = pd.read_csv(folder_path+f\"\\\\parametric\\\\{df.loc[i, 'Name']}_residuals_report.csv\")\n",
    "    mdot_report[df.loc[i, 'Name']] = pd.read_csv(folder_path+f\"\\\\parametric\\\\{df.loc[i, 'Name']}_mdot_report.csv\")\n",
    "    pressure_report[df.loc[i, 'Name']] = pd.read_csv(folder_path+f\"\\\\parametric\\\\{df.loc[i, 'Name']}_pressure_report.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    df.loc[i, 'last_continuity_residual'] = residuals_report[df.loc[i, \"Name\"]].iloc[-1]['continuity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_convergence(row):\n",
    "    if row['last_continuity_residual'] < 1e-1 and row['last_continuity_residual'] > 1e-2:\n",
    "        return -1\n",
    "    elif row['last_continuity_residual'] < 1e-2 and row['last_continuity_residual'] > 1e-3:\n",
    "        return -2\n",
    "    elif row['last_continuity_residual'] < 1e-3 and row['last_continuity_residual'] > 1e-4:\n",
    "        return -3\n",
    "    elif row['last_continuity_residual'] < 1e-4 and row['last_continuity_residual'] > 1e-5:\n",
    "        return -4\n",
    "    # Add more conditions as needed\n",
    "    elif row['last_continuity_residual'] < 1e-5 and row['last_continuity_residual'] > 1e-6:\n",
    "        return -5\n",
    "    elif row['last_continuity_residual'] < 1e-6 and row['last_continuity_residual'] > 1e-7:\n",
    "        return -6\n",
    "    # Default value if no condition is met\n",
    "    return None\n",
    "\n",
    "df['convergence'] = df.apply(set_convergence, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = mdot_report['DP1']['Component'].unique()\n",
    "new_columns = [f'DP{i}' for i in range(1, 101)]\n",
    "mdot_df = pd.DataFrame(index=components, columns=new_columns)\n",
    "\n",
    "for indew, row in df.iterrows():\n",
    "    name = row['Name']\n",
    "    temp = mdot_report[name]\n",
    "    for component in components:\n",
    "        mdot_df.at[component, name] = temp.loc[temp['Component'] == component].drop_duplicates()['Mass Flow Rate'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    case = df.loc[i, 'Name']\n",
    "    df.loc[i, 'sp_coll_inlet'] = pressure_report[case][pressure_report[case]['Component'] == 'coll_inlet']['Value'].values[0]\n",
    "    df.loc[i, 'sp_coll_outlet'] = pressure_report[case][pressure_report[case]['Component'] == 'coll_outlet']['Value'].values[0]\n",
    "    df.loc[i, 'sp_distrib_inlet'] = pressure_report[case][pressure_report[case]['Component'] == 'distrib_inlet']['Value'].values[0]\n",
    "    df.loc[i, 'sp_distrib_outlet'] = pressure_report[case][pressure_report[case]['Component'] == 'distrib_outlet']['Value'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DPd'] = df['sp_distrib_inlet'] - df['sp_distrib_outlet']\n",
    "df['DPc'] = df['sp_coll_inlet'] - df['sp_coll_outlet']\n",
    "df['DPdc'] = df['sp_distrib_outlet'] - df['sp_coll_inlet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of DP values\n",
    "dp_range = range(1, 101)\n",
    "\n",
    "# Define the range of coll_ch values\n",
    "coll_ch_range = range(1, 17)\n",
    "\n",
    "# Create a Plotly Figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over DP values\n",
    "for dp in dp_range:\n",
    "    # Get the mass flow rate values for the coll_ch values\n",
    "    coll_ch_mass_flow_rates = [mdot_df.at[f'coll_ch{i}', f'DP{dp}'] for i in coll_ch_range]\n",
    "    distrib_ch_mass_flow_rates = [-mdot_df.at[f'distrib_ch{i}', f'DP{dp}'] for i in coll_ch_range]\n",
    "\n",
    "    \n",
    "    # Add scatter plot to the figure\n",
    "    fig.add_trace(go.Scatter(x=list(coll_ch_range), y=coll_ch_mass_flow_rates,\n",
    "                             mode='markers', name=f'DP{dp}_coll_ch'))\n",
    "    fig.add_trace(go.Scatter(x=list(coll_ch_range), y=distrib_ch_mass_flow_rates,\n",
    "                                mode='markers', name=f'DP{dp}_distrib_ch'))\n",
    "\n",
    "# Update layout with labels and title\n",
    "fig.update_layout(title='Mass Flow Rate for coll_ch1 to coll_ch16',\n",
    "                  xaxis_title='coll_ch',\n",
    "                  yaxis_title='Mass Flow Rate',\n",
    "                  legend_title='DP Values')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'distrib_inlet_mdot/Q_max':'beta'},inplace=True)\n",
    "\n",
    "df_fil = df[df['Vdot_max'] == 200]\n",
    "# df_fil = df_fil[df_fil['converged']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_excel(r'D:\\ANSYS Fluent Projects\\Hydraulics\\V4.5\\1MPE\\AbaqueCFD_V4.5_MPE_x1.xlsx')\n",
    "\n",
    "df_full['DPd'] = df_full['sp_distrib_inlet'] - df_full['sp_distrib_outlet']\n",
    "df_full['DPc'] = df_full['sp_coll_inlet'] - df_full['sp_coll_outlet']\n",
    "df_full['DPdc'] = df_full['sp_coll_inlet'] - df_full['sp_distrib_outlet']\n",
    "\n",
    "df_full_fil = df_full[df_full['Vdot_max'] == 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1d = pd.read_excel(r'G:\\Drive partagés\\Cercle Hard\\Notion\\PRJ-1088 - CFD pour la caractérisation hydraulique d’un échangeur à mini-canaux\\1D_V4.5_MPE_sans calibrage\\Abaque_1MPE_200Lh.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ['beta','alpha']\n",
    "Y_list = ['DPd','DPc','DPdc']\n",
    "\n",
    "fig_cfd_list = ppproc.plot_Y_X(df_fil, X_list, Y_list)\n",
    "fig_1d_list = ppproc.plot_Y_X(df1d, X_list, Y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fig_list = []  # This will store the combined figures\n",
    "\n",
    "for i in range(len(fig_cfd_list)):\n",
    "    combined_fig = go.Figure()\n",
    "    fig = fig_cfd_list[i]\n",
    "    fig2 = fig_1d_list[i]\n",
    "\n",
    "    # Extract each trace from this figure and add it to the combined_fig\n",
    "    for trace in fig.data:\n",
    "        if trace['mode'] == 'lines':\n",
    "            mtrace = trace\n",
    "            mtrace['name'] = mtrace['name'] + \" (cfd)\"\n",
    "            combined_fig.add_trace(mtrace)\n",
    "        else:\n",
    "            pass\n",
    "    for trace in fig2.data:\n",
    "        if trace['mode'] == 'lines':\n",
    "            mtrace = trace\n",
    "            mtrace['name'] = mtrace['name'] + \" (1d)\"\n",
    "            combined_fig.add_trace(trace)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    combined_fig['layout'] = fig['layout']\n",
    "\n",
    "    combined_fig_list.append(combined_fig)\n",
    "\n",
    "for fig in combined_fig_list:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfun.write_fig_list_one_html(fig_list, len(fig_list)*[\"\"], 'AbaqueCFD_1MPE_600Lh.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3d = []\n",
    "\n",
    "X1_name = 'alpha'\n",
    "X2_name = 'beta'\n",
    "# Y_name = 'DPd'\n",
    "\n",
    "for Y_name in ['DPd','DPc','DPdc']:\n",
    "\n",
    "    dff = df_fil[[X1_name, X2_name, Y_name]]\n",
    "\n",
    "    # Prepare the data for interpolation\n",
    "    points = dff[[X1_name, X2_name]].values  # The (X1, X2) pairs\n",
    "    values = dff[Y_name].values  # The Y values\n",
    "\n",
    "    # Define the interpolation function\n",
    "    def interpolate(x1, x2):\n",
    "        # Single point (x1, x2) for which to interpolate the value\n",
    "        point = np.array([[x1, x2]])\n",
    "        # Perform interpolation\n",
    "        y_interp = sci.griddata(points, values, point, method='linear')\n",
    "        return y_interp[0]\n",
    "\n",
    "    # Create a meshgrid for X1_name\n",
    "    x1_range = np.linspace(0, 1, 100)\n",
    "    x2_range = np.linspace(0, 1, 100)\n",
    "    x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    # Use the interpolate function over the grid\n",
    "    y_grid = np.array([interpolate(x1, x2) for x1, x2 in zip(x1_grid.flatten(), x2_grid.flatten())])\n",
    "    y_grid = y_grid.reshape(x1_grid.shape)\n",
    "\n",
    "    # X1_name\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the surface plot\n",
    "    fig.add_trace(go.Surface(x=x1_grid, y=x2_grid, z=y_grid, name='Interpolated Surface', colorscale='Viridis'))\n",
    "\n",
    "    # Add the original data points as scatter plot\n",
    "    fig.add_trace(go.Scatter3d(x=dff[X1_name], y=dff[X2_name], z=dff[Y_name], mode='markers', \n",
    "                            marker=dict(size=5, color='red'), name='Original Data'))\n",
    "\n",
    "    fig.update_layout(title='3D Surface and Points Plot', autosize=False,\n",
    "                    width=700, height=700,\n",
    "                    margin=dict(l=65, r=50, b=65, t=90))\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis_title=X1_name,\n",
    "                        yaxis_title=X2_name,\n",
    "                        zaxis_title=Y_name))\n",
    "\n",
    "    fig3d.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfun.write_fig_list_one_html(fig3d, ['DPd','DPc','DPdc'], '1MPE_600Lh_3D_plots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'G:\\Drive partagés\\Cercle Hard\\Notion\\PRJ-1088 - CFD pour la caractérisation hydraulique d’un échangeur à mini-canaux\\AbaqueCFD_1MPE_woch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([\n",
    "#     df_fil[X1_name]**2 * df_fil[X2_name]**2,  # X1^2 * X2^2\n",
    "#     df_fil[X1_name] * df_fil[X2_name]**2,    # X1 * X2^2\n",
    "#     df_fil[X2_name]**2,               # X2^2\n",
    "#     df_fil[X1_name]**2 * df_fil[X2_name],    # X1^2 * X2\n",
    "#     df_fil[X1_name] * df_fil[X2_name],       # X1 * X2\n",
    "#     df_fil[X2_name],                  # X2\n",
    "#     df_fil[X1_name]**2,               # X1^2\n",
    "#     df_fil[X1_name],                  # X1\n",
    "#     np.ones(len(df_fil))           # Intercept (constant)\n",
    "# ]).T  # Transpose to get the correct shape\n",
    "\n",
    "# Y = df_fil[Y_name].values\n",
    "\n",
    "# # Fit the model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X, Y)\n",
    "\n",
    "# # Coefficients\n",
    "# a2, b2, c2, a1, b1, c1, a0, b0, c0 = model.coef_\n",
    "\n",
    "# # Intercept (should be very close to c0 because of the way we structured the equation)\n",
    "# intercept = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_name = 'DPd'\n",
    "\n",
    "X_columns = df_fil[[X1_name, X2_name]]\n",
    "\n",
    "# Generate polynomial features up to the third degree\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_columns)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, df_fil[Y_name])\n",
    "\n",
    "# Coefficients\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Generate a grid for plotting\n",
    "x1_range = np.linspace(df_fil[X1_name].min(), df_fil[X1_name].max(), 50)\n",
    "x2_range = np.linspace(df_fil[X2_name].min(), df_fil[X2_name].max(), 50)\n",
    "x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Flatten the grid to apply transformations\n",
    "X_grid = np.vstack([x1_grid.ravel(), x2_grid.ravel()]).T\n",
    "\n",
    "# Generate polynomial features for the grid\n",
    "X_grid_poly = poly.transform(X_grid)\n",
    "\n",
    "# Predict Y values over the grid\n",
    "y_pred_grid = model.predict(X_grid_poly).reshape(x1_grid.shape)\n",
    "\n",
    "# Step 1: Generate a grid\n",
    "x1_range = np.linspace(df_fil[X1_name].min(), df_fil[X1_name].max(), 100)\n",
    "x2_range = np.linspace(df_fil[X2_name].min(), df_fil[X2_name].max(), 100)\n",
    "x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Flatten the grid to apply transformations\n",
    "X_grid = np.vstack([x1_grid.ravel(), x2_grid.ravel()]).T\n",
    "\n",
    "# Generate polynomial features for the grid\n",
    "X_grid_poly = poly.transform(X_grid)\n",
    "\n",
    "# Predict Y values over the grid\n",
    "y_pred_grid = model.predict(X_grid_poly).reshape(x1_grid.shape)\n",
    "\n",
    "# Step 3: Plot the surface\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(x=x1_grid, y=x2_grid, z=y_pred_grid, name='Interpolated Surface', colorscale='Viridis'))\n",
    "\n",
    "# Step 4: Overlay the original data points\n",
    "fig.add_trace(go.Scatter3d(x=df_fil[X1_name], y=df_fil[X2_name], z=df_fil[Y_name], mode='markers', \n",
    "                           marker=dict(size=5, color='red'), name='Original Data'))\n",
    "\n",
    "# Update plot layout\n",
    "fig.update_layout(title='3D Surface and Points Plot', autosize=False,\n",
    "                  width=700, height=700,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90),\n",
    "                  scene=dict(\n",
    "                      xaxis_title=X1_name,\n",
    "                      yaxis_title=X2_name,\n",
    "                      zaxis_title=Y_name))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Step 1: Use the model to predict Y values for the original data points\n",
    "Y_pred = model.predict(X_poly)  # X_poly contains the polynomial features of the original data\n",
    "\n",
    "# Step 2: Calculate the differences (errors) between predicted and actual Y values\n",
    "Y_actual = df_fil[Y_name].values  # Actual Y values from the DataFrame\n",
    "\n",
    "# Step 3: Compute the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(Y_actual, Y_pred))\n",
    "\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py_ansys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
