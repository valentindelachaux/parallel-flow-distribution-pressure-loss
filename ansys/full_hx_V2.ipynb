{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import jou_gen as jg\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "import ansys.fluent.core as pyfluent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\ANSYS Fluent Projects\\Hydraulics\\V4.5\\19MPE_woch\\fluent'\n",
    "\n",
    "N_junction = 38\n",
    "N_channels = 304\n",
    "Area_junction = 44.0414E-6\n",
    "\n",
    "N_big_it = 25\n",
    "N_it = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df,mdot_distrib_inlet):\n",
    "\n",
    "    positive_count = (df['mdot'] > 0).sum()\n",
    "    null_count = (df['mdot'] == 0).sum()\n",
    "\n",
    "    if positive_count > 0:\n",
    "\n",
    "        perc_to_adjust = ( 1 - mdot_distrib_inlet/-df[df['mdot'] < 0]['mdot'].sum() )\n",
    "        perc_to_distribute = 0.01\n",
    "        mdot_to_distribute = perc_to_distribute * -df[df['mdot'] < 0]['mdot'].sum()\n",
    "        perc_to_remove = perc_to_adjust + perc_to_distribute\n",
    "\n",
    "        df['mdot_updated'] = np.where(df['mdot'] < 0, (1-perc_to_remove)*df['mdot'], mdot_to_distribute / positive_count)\n",
    "        df['mdot'] = df['mdot_updated'].abs()\n",
    "\n",
    "    elif null_count > 0:\n",
    "\n",
    "        perc_to_distribute = 0.05\n",
    "        mdot_to_distribute = perc_to_distribute * -df[df['mdot'] < 0]['mdot'].sum()\n",
    "\n",
    "        df['mdot_updated'] = np.where(df['mdot'] < 0, (1-perc_to_distribute)*df['mdot'], mdot_to_distribute / null_count)\n",
    "        df['mdot'] = df['mdot_updated'].abs()\n",
    "\n",
    "    else:\n",
    "        df['mdot'] = df['mdot'].abs()\n",
    "\n",
    "    df['mdot_ch_norm'] = df['mdot']/(df['mdot'].sum()/N_junction)\n",
    "    df['new_input'] = df['mdot_ch_norm'] * (mdot_distrib_inlet/N_junction)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_path = folder_path + '\\\\' + 'server_info-23956.txt'\n",
    "solver = pyfluent.connect_to_fluent(server_info_filepath=solver_path)\n",
    "tui = solver.tui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path + '\\\\' + 'create_mdot_report_CPH.txt', \"w\") as file:\n",
    "    file.write(jg.write_report_massflow(folder_path+'\\\\CPH\\\\'+'mdot_report.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path + '\\\\' + 'create_sp_report_CPH.txt', \"w\") as file:\n",
    "    file.write(jg.write_report_sp_prepared(folder_path+'\\\\CPH\\\\'+'sp_report.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tui.file.read_journal('CPH\\\\create_mdot_report_CPH.txt')\n",
    "tui.file.read_journal('CPH\\\\create_sp_report_CPH.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jg.convert_report(folder_path+'\\\\CPH','mdot_report.txt','mdot',output_file_name_wo_extension='mdot_report_IT1')\n",
    "jg.convert_report(folder_path+'\\\\CPH','sp_report.txt','sp',output_file_name_wo_extension='sp_report_IT1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder_path+'\\\\CPH\\\\mdot_report_IT1.csv')\n",
    "df2 = pd.read_csv(folder_path+'\\\\CPH\\\\sp_report_IT1.csv')\n",
    "\n",
    "merged_df = pd.merge(df, df2, on='Component')\n",
    "dff = merged_df[merged_df['Component'].str.contains('coll_ch|distrib_ch')]\n",
    "dff['Component'].astype(str)\n",
    "\n",
    "coll_df = dff[dff['Component'].str.contains('coll_ch')].copy()\n",
    "coll_df['index'] = coll_df['Component'].str.extract(r'coll_ch_(\\d+)')\n",
    "coll_df.dropna(subset='index', inplace=True)\n",
    "coll_df['index'] = coll_df['index'].astype(int)\n",
    "coll_df.sort_values(by='index', inplace=True)\n",
    "coll_df.set_index('index', inplace=True, drop=True)\n",
    "\n",
    "distrib_df = dff[dff['Component'].str.contains('distrib_ch')].copy()\n",
    "distrib_df['index'] = distrib_df['Component'].str.extract(r'distrib_ch_(\\d+)')\n",
    "distrib_df.dropna(subset='index', inplace=True)\n",
    "distrib_df['index'] = distrib_df['index'].astype(int)\n",
    "distrib_df.sort_values(by='index', inplace=True)\n",
    "distrib_df.set_index('index', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distrib_df.index,distrib_df['mdot'])\n",
    "plt.plot(coll_df.index,coll_df['mdot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_df['sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distrib_df.index,distrib_df['sp'],label='distrib')\n",
    "plt.plot(coll_df.index,coll_df['sp'],label='coll')\n",
    "plt.plot(coll_df.index,coll_df['sp'] + 1411785 * (coll_df['mdot'] / 8),label='coll + 1411785 * (mdot / 8)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_df_P = process_df(distrib_df,merged_df[merged_df['Component'] == 'distrib_inlet']['mdot'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'issue de l'itération N\n",
    "\n",
    "Etape 1\n",
    "\n",
    "On met le profil de débits obtenus en sortie de distributeur -> en entrée du collecteur\n",
    "On met en condition à la limite en sortie du distributeur la valeur de pression mesurée en entrée du collecteur + coeff * débit mis en entrée collecteur, et un target mass flow rate = à \n",
    "l'opposé du débit mesuré en entrée collecteur\n",
    "\n",
    "On fait tourner\n",
    "\n",
    "Etape 2\n",
    "\n",
    "On actualise les valeurs de pression en sortie du distributeur avec ce qu'on a obtenu en entrée collecteur + coeff * débit entrée collecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = []\n",
    "\n",
    "for i in range(N_junction):\n",
    "    string_list.append(jg.change_bc_velocity_inlet(f\"coll_ch_{i+1}\",f\"( {{mdot_distrib_ch_{i+1}}} / rho_water ) / (44.0414E-6 [m^2])\"))\n",
    "\n",
    "jg.concatenate_and_write_to_file(string_list,folder_path+'\\\\CPH\\\\'+'change_bc_v_CPH_last_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with target mass flow\n",
    "\n",
    "string_list = []\n",
    "for i in range(N_junction):\n",
    "    sp_value = coll_df.loc[i+1,'sp'] + 1411785 * (distrib_df.loc[i+1,'new_input'] / 8)\n",
    "    string_list.append(f\"\"\"\n",
    "define/boundary-conditions/pressure-outlet distrib_ch_{i+1} yes no {sp_value} no no yes yes no no yes no {distrib_df.loc[i+1,'new_input']} no 5000000 no 1\"\"\")\n",
    "jg.concatenate_and_write_to_file(string_list,folder_path + '\\\\CPH\\\\' + 'change_bc_po_non_uniform_target_CPH.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### without target mass flow\n",
    "\n",
    "string_list = []\n",
    "for i in range(N_junction):\n",
    "    sp_value = coll_df.loc[i+1,'sp'] + 1411785 * (distrib_df.loc[i+1,'new_input'] / 8)\n",
    "    string_list.append(f\"\"\"\n",
    "define/boundary-conditions/pressure-outlet distrib_ch_{i+1} yes no {sp_value} no no yes yes no no no\"\"\")\n",
    "jg.concatenate_and_write_to_file(string_list,folder_path + '\\\\CPH\\\\' + 'change_bc_po_non_uniform_without_target_CPH.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_BC yes no value no no yes yes no no yes no \"{{mdot_coll_ch_{i}}}\" no 5000000 no 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAST TEST\n",
    "\n",
    "string_list = []\n",
    "for i in range(N_junction):\n",
    "    string_list.append(f\"\"\"\n",
    "define/boundary-conditions/pressure-outlet distrib_ch_{i+1} yes no \"{{sp_coll_ch_{i+1}}} + 1411785 [Pa s / kg] * ( {{mdot_coll_ch_{i+1}}} / 8)\" no no yes yes no no yes no \"{{mdot_coll_ch_{i+1}}}\" no 5000000 no 1\"\"\")\n",
    "jg.concatenate_and_write_to_file(string_list,folder_path + '\\\\CPH\\\\' + 'change_bc_po_non_uniform_CPH_LAST_TEST.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tui.file.read_journal('CPH\\\\change_bc_v_CPH_last_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tui.file.read_journal('CPH\\\\change_bc_po_non_uniform_CPH_LAST_TEST.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py_ansys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
